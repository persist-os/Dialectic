# ðŸ—ï¸ Dialectic: Technical Architecture - Self-Learning Cursor Community

## ðŸŽ¯ System Overview

**Dialectic** is an autonomous community of AI agents that continuously learns from your codebase and maintains your `.cursor` folder without human intervention.

## ðŸ›ï¸ Core Architecture

### **System Components**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DIALECTIC ECOSYSTEM                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Event Detection  â”‚  Dynamic Agent  â”‚  Documentation        â”‚
â”‚  (Sentry MCP)     â”‚  Generation     â”‚  Maintenance         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Redpanda      â”‚     StackAI     â”‚     Your .cursor      â”‚
â”‚   (A2A Streams)   â”‚  (Orchestration)â”‚     Folder           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Real-time Events â”‚  Agent Learning â”‚  Self-Improving      â”‚
â”‚  Code Changes     â”‚  Pattern Recognition â”‚  Knowledge Base  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ§  Dynamic Agent Generation System

### **Event-Driven Agent Creation**

```python
class DynamicAgentGenerator:
    """Generates agents based on codebase context and development events"""
    
    def __init__(self, sentry_client, redpanda_client):
        self.sentry = sentry_client
        self.redpanda = redpanda_client
        self.learning_engine = LearningEngine()
    
    async def analyze_codebase_context(self, event_data):
        """Analyze codebase context to determine needed agents"""
        
        context = {
            'files_changed': event_data.get('files', []),
            'commit_message': event_data.get('message', ''),
            'error_patterns': await self.sentry.get_error_patterns(),
            'development_focus': await self.detect_development_focus(event_data)
        }
        
        return context
    
    async def generate_contextual_agents(self, context):
        """Generate agents based on actual codebase needs"""
        
        agents = []
        
        # Security focus detection
        if self.needs_security_focus(context):
            agents.append(await self.create_security_agent(context))
        
        # MVP focus detection
        if self.needs_mvp_focus(context):
            agents.append(await self.create_mvp_agent(context))
        
        # Performance focus detection
        if self.needs_performance_focus(context):
            agents.append(await self.create_performance_agent(context))
        
        # Documentation focus detection
        if self.needs_documentation_focus(context):
            agents.append(await self.create_documentation_agent(context))
        
        return agents
    
    def needs_security_focus(self, context):
        """Detect if codebase needs security focus"""
        security_keywords = ['auth', 'password', 'token', 'security', 'encrypt', 'permission']
        files_changed = context.get('files_changed', [])
        commit_message = context.get('commit_message', '').lower()
        
        return (any(keyword in str(files_changed).lower() for keyword in security_keywords) or
                any(keyword in commit_message for keyword in security_keywords))
    
    def needs_mvp_focus(self, context):
        """Detect if codebase needs MVP focus"""
        mvp_keywords = ['prototype', 'mvp', 'quick', 'rapid', 'hackathon', 'demo']
        commit_message = context.get('commit_message', '').lower()
        
        return any(keyword in commit_message for keyword in mvp_keywords)
    
    def needs_performance_focus(self, context):
        """Detect if codebase needs performance focus"""
        performance_keywords = ['optimize', 'performance', 'speed', 'cache', 'async']
        files_changed = context.get('files_changed', [])
        commit_message = context.get('commit_message', '').lower()
        
        return (any(keyword in str(files_changed).lower() for keyword in performance_keywords) or
                any(keyword in commit_message for keyword in performance_keywords))
    
    def needs_documentation_focus(self, context):
        """Detect if codebase needs documentation focus"""
        doc_keywords = ['readme', 'docs', 'documentation', 'guide', 'tutorial']
        files_changed = context.get('files_changed', [])
        
        return any(keyword in str(files_changed).lower() for keyword in doc_keywords)

class DynamicAgentGenerator:
    """Generates specialized agents based on question analysis"""
    
    def __init__(self, openai_client, airia_client):
        self.openai = openai_client
        self.airia = airia_client
    
    async def generate_agents(self, analysis: QuestionAnalysis) -> List[GeneratedAgent]:
        """Generate specialized agents based on question analysis"""
        
        agents = []
        
        # Generate agent for each identified dimension
        for dimension in analysis.dimensions:
            agent = await self._create_dimension_agent(dimension, analysis)
            agents.append(agent)
        
        # Ensure balanced perspective coverage
        if not self._has_balanced_perspectives(agents):
            additional_agents = await self._generate_balancing_agents(analysis, agents)
            agents.extend(additional_agents)
        
        return agents
    
    async def _create_dimension_agent(self, dimension: str, analysis: QuestionAnalysis) -> GeneratedAgent:
        """Create specialized agent for specific dimension"""
        
        # Generate agent personality and expertise
        agent_prompt = f"""
        Create a specialized AI agent for this dimension: {dimension}
        
        Question: {analysis.question}
        Context: {analysis}
        
        Define:
        1. Agent role and name
        2. Core perspective and reasoning framework
        3. Expertise domains
        4. Evaluation criteria
        5. System prompt for the agent
        
        Make this agent highly specialized and unbiased for the {dimension} dimension.
        """
        
        agent_spec = await self.openai.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": agent_prompt}]
        )
        
        agent_data = json.loads(agent_spec.choices[0].message.content)
        
        # Load relevant knowledge from Airia
        knowledge_context = await self.airia.query_domain_specific(
            question=analysis.question,
            domain=dimension,
            perspective=agent_data["perspective"]
        )
        
        return GeneratedAgent(
            id=f"{dimension.lower().replace(' ', '_')}_agent",
            role=agent_data["role"],
            name=agent_data["name"],
            perspective=agent_data["perspective"],
            expertise=agent_data["expertise"],
            evaluation_criteria=agent_data["criteria"],
            system_prompt=agent_data["system_prompt"],
            knowledge_context=knowledge_context,
            voting_weight=1.0
        )
    
    def _has_balanced_perspectives(self, agents: List[GeneratedAgent]) -> bool:
        """Check if agents provide balanced perspective coverage"""
        
        # Check for pro/con balance
        has_pro_perspective = any("support" in agent.perspective.lower() or "positive" in agent.perspective.lower() for agent in agents)
        has_con_perspective = any("challenge" in agent.perspective.lower() or "negative" in agent.perspective.lower() for agent in agents)
        
        # Check for different time horizons
        has_short_term = any("short" in agent.perspective.lower() or "immediate" in agent.perspective.lower() for agent in agents)
        has_long_term = any("long" in agent.perspective.lower() or "future" in agent.perspective.lower() for agent in agents)
        
        return has_pro_perspective and has_con_perspective and has_short_term and has_long_term
    
    async def _generate_balancing_agents(self, analysis: QuestionAnalysis, existing_agents: List[GeneratedAgent]) -> List[GeneratedAgent]:
        """Generate additional agents to ensure balanced perspective"""
        
        balancing_agents = []
        
        # Generate opposing perspective agent
        if not self._has_opposing_perspective(existing_agents):
            opposing_agent = await self._create_opposing_agent(analysis, existing_agents)
            balancing_agents.append(opposing_agent)
        
        # Generate long-term perspective agent
        if not self._has_long_term_perspective(existing_agents):
            long_term_agent = await self._create_long_term_agent(analysis)
            balancing_agents.append(long_term_agent)
        
        return balancing_agents
```

### **Custom Agent Builder**

```python
class CustomAgentBuilder:
    """Dynamic agent creation system"""
    
    async def create_agent(
        self, 
        name: str, 
        perspective: str, 
        expertise_domains: List[str],
        voting_weight: float = 1.0
    ) -> AgentTemplate:
        """Create a custom agent with user-defined characteristics"""
        
        # Generate system prompt based on user input
        system_prompt = self._generate_system_prompt(name, perspective, expertise_domains)
        
        # Create agent with specialized knowledge base
        agent = AgentTemplate(
            role=name,
            perspective=perspective,
            expertise=expertise_domains
        )
        
        # Load relevant knowledge from Airia
        agent.knowledge_base = await self._load_knowledge_domains(expertise_domains)
        
        return agent
    
    def _generate_system_prompt(self, name: str, perspective: str, domains: List[str]) -> str:
        return f"""
        You are {name}, an AI agent specialized in {', '.join(domains)}.
        
        Your perspective: {perspective}
        
        When participating in debates:
        1. Always ground your arguments in evidence from your expertise domains
        2. Consider multiple angles within your perspective
        3. Acknowledge valid counterarguments from other agents
        4. Vote based on your analysis, not just your initial bias
        5. Learn from the debate and update your understanding
        
        Your goal is to contribute to finding the best possible answer through
        structured reasoning and collaborative debate.
        """
```

## ðŸŒŠ Debate Orchestration Engine

### **Debate Flow Architecture**

```python
class DebateOrchestrator:
    """Manages the complete debate lifecycle"""
    
    def __init__(self, redpanda_client, airia_client, stackai_client):
        self.message_bus = redpanda_client
        self.knowledge = airia_client
        self.workflow = stackai_client
        self.active_debates = {}
    
    async def start_debate(
        self, 
        question: str, 
        agents: List[AgentTemplate],
        debate_rounds: int = 3
    ) -> DebateSession:
        """Initialize a new debate session"""
        
        # Create debate session
        session = DebateSession(
            question=question,
            agents=agents,
            rounds=debate_rounds,
            status="initializing"
        )
        
        # Load context from Airia
        context = await self._load_debate_context(question, agents)
        session.context = context
        
        # Initialize agent states
        for agent in agents:
            agent.current_position = await agent.form_initial_position(question, context)
        
        # Start Redpanda streams for real-time communication
        await self._setup_communication_streams(session)
        
        return session
    
    async def conduct_debate_round(self, session: DebateSession) -> DebateRound:
        """Execute a single round of debate"""
        
        round_data = DebateRound(
            round_number=session.current_round,
            question=session.question,
            context=session.context
        )
        
        # Phase 1: Opening Statements
        opening_statements = []
        for agent in session.agents:
            statement = await agent.make_opening_statement(
                session.question, 
                session.context,
                other_agents=session.agents
            )
            opening_statements.append(statement)
            
            # Stream to frontend via Redpanda
            await self.message_bus.produce(
                topic=f"debate_{session.id}_statements",
                value=statement
            )
        
        round_data.opening_statements = opening_statements
        
        # Phase 2: Rebuttal and Discussion
        for rebuttal_round in range(2):  # 2 rounds of rebuttals
            rebuttals = []
            for agent in session.agents:
                rebuttal = await agent.make_rebuttal(
                    previous_statements=opening_statements,
                    current_round=rebuttal_round
                )
                rebuttals.append(rebuttal)
                
                # Stream rebuttals
                await self.message_bus.produce(
                    topic=f"debate_{session.id}_rebuttals",
                    value=rebuttal
                )
            
            round_data.rebuttals.append(rebuttals)
        
        # Phase 3: Voting
        votes = await self._collect_votes(session.agents, session.question)
        round_data.votes = votes
        
        # Phase 4: Consensus Calculation
        consensus = await self._calculate_consensus(votes, session.agents)
        round_data.consensus = consensus
        
        return round_data
```

## ðŸ—³ï¸ Democratic Decision Making

### **Voting System**

```python
class DemocraticVoting:
    """Implements sophisticated voting mechanisms"""
    
    async def collect_votes(
        self, 
        agents: List[AgentTemplate], 
        question: str,
        options: List[str] = None
    ) -> List[Vote]:
        """Collect votes from all agents with reasoning"""
        
        votes = []
        for agent in agents:
            vote = await agent.vote(
                question=question,
                options=options,
                debate_context=self.current_debate_context,
                other_agents=self.current_debate_agents
            )
            
            # Enhance vote with confidence and reasoning
            enhanced_vote = Vote(
                agent_id=agent.role,
                choice=vote.choice,
                confidence=vote.confidence,
                reasoning=vote.reasoning,
                alternatives_considered=vote.alternatives,
                voting_weight=agent.voting_weight
            )
            
            votes.append(enhanced_vote)
            
            # Stream vote to frontend
            await self.message_bus.produce(
                topic=f"debate_{self.session_id}_votes",
                value=enhanced_vote
            )
        
        return votes
    
    async def calculate_consensus(
        self, 
        votes: List[Vote]
    ) -> Consensus:
        """Calculate weighted consensus with confidence levels"""
        
        # Weighted voting
        weighted_scores = {}
        total_confidence = 0
        
        for vote in votes:
            choice = vote.choice
            weight = vote.voting_weight
            confidence = vote.confidence
            
            if choice not in weighted_scores:
                weighted_scores[choice] = 0
            
            weighted_scores[choice] += weight * confidence
            total_confidence += confidence
        
        # Find consensus
        if not weighted_scores:
            return Consensus(
                primary_choice=None,
                confidence=0.0,
                distribution={},
                reasoning="No votes collected"
            )
        
        primary_choice = max(weighted_scores.items(), key=lambda x: x[1])
        
        # Calculate distribution
        distribution = {}
        for choice, score in weighted_scores.items():
            distribution[choice] = score / sum(weighted_scores.values())
        
        # Generate consensus reasoning
        reasoning = await self._generate_consensus_reasoning(votes, primary_choice)
        
        return Consensus(
            primary_choice=primary_choice[0],
            confidence=primary_choice[1] / total_confidence,
            distribution=distribution,
            reasoning=reasoning,
            individual_votes=votes
        )
```

## ðŸ“Š Knowledge Integration (Airia)

### **Context Loading System**

```python
class KnowledgeIntegration:
    """Integrates Airia knowledge base with debate context"""
    
    async def load_debate_context(
        self, 
        question: str, 
        agents: List[AgentTemplate]
    ) -> DebateContext:
        """Load relevant knowledge for debate context"""
        
        # Extract key concepts from question
        concepts = await self._extract_concepts(question)
        
        # Gather knowledge for each agent's expertise
        knowledge_sets = {}
        for agent in agents:
            agent_knowledge = await self.airia_client.query(
                question=question,
                domains=agent.expertise,
                depth="comprehensive",
                sources=True
            )
            knowledge_sets[agent.role] = agent_knowledge
        
        # Find common ground and conflicts
        common_ground = await self._find_common_ground(knowledge_sets)
        conflicts = await self._identify_conflicts(knowledge_sets)
        
        return DebateContext(
            question=question,
            concepts=concepts,
            agent_knowledge=knowledge_sets,
            common_ground=common_ground,
            conflicts=conflicts,
            sources=self._extract_sources(knowledge_sets)
        )
    
    async def _find_common_ground(self, knowledge_sets: Dict) -> List[CommonGround]:
        """Identify areas of agreement between agent knowledge bases"""
        
        common_grounds = []
        
        # Find overlapping evidence
        for agent1, knowledge1 in knowledge_sets.items():
            for agent2, knowledge2 in knowledge_sets.items():
                if agent1 != agent2:
                    overlap = await self._find_knowledge_overlap(knowledge1, knowledge2)
                    if overlap:
                        common_grounds.append(CommonGround(
                            agents=[agent1, agent2],
                            shared_knowledge=overlap,
                            strength=len(overlap)
                        ))
        
        return common_grounds
```

## ðŸ”„ Real-time Communication (Redpanda)

### **Message Streaming System**

```python
class DebateStreaming:
    """Manages real-time communication via Redpanda streams"""
    
    def __init__(self, redpanda_client):
        self.rp = redpanda_client
        self.active_streams = {}
    
    async def setup_debate_streams(self, session_id: str):
        """Initialize all streams for a debate session"""
        
        streams = {
            "statements": f"debate_{session_id}_statements",
            "rebuttals": f"debate_{session_id}_rebuttals", 
            "votes": f"debate_{session_id}_votes",
            "consensus": f"debate_{session_id}_consensus",
            "agent_state": f"debate_{session_id}_agent_state"
        }
        
        for stream_type, topic in streams.items():
            await self.rp.create_topic(topic)
            self.active_streams[stream_type] = topic
        
        return streams
    
    async def stream_agent_message(
        self, 
        session_id: str, 
        message_type: str, 
        content: Dict
    ):
        """Stream agent message to frontend"""
        
        message = {
            "timestamp": datetime.utcnow().isoformat(),
            "session_id": session_id,
            "type": message_type,
            "content": content
        }
        
        topic = self.active_streams.get(message_type)
        if topic:
            await self.rp.produce(topic, message)
    
    async def subscribe_to_debate(self, session_id: str, callback):
        """Subscribe to all streams for a debate"""
        
        streams = self.active_streams
        
        async def stream_consumer():
            for stream_type, topic in streams.items():
                async for message in self.rp.consume(topic):
                    await callback(message)
        
        return stream_consumer()
```

## ðŸŽ¨ Frontend Architecture

### **React Component Structure**

```typescript
// Core Components
interface DebateSession {
  id: string;
  question: string;
  agents: Agent[];
  rounds: DebateRound[];
  status: 'active' | 'completed' | 'paused';
}

interface Agent {
  id: string;
  role: string;
  perspective: string;
  expertise: string[];
  currentPosition: string;
  votingHistory: Vote[];
  confidence: number;
}

// Main Debate Interface
const DebateInterface: React.FC<{ sessionId: string }> = ({ sessionId }) => {
  const [session, setSession] = useState<DebateSession | null>(null);
  const [activeRound, setActiveRound] = useState<number>(0);
  const [realTimeUpdates, setRealTimeUpdates] = useState<Message[]>([]);
  
  // Real-time updates via WebSocket
  useEffect(() => {
    const ws = new WebSocket(`ws://localhost:8000/ws/debate/${sessionId}`);
    
    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);
      setRealTimeUpdates(prev => [...prev, message]);
      
      // Update session state based on message type
      if (message.type === 'statement') {
        updateAgentStatement(message.agent_id, message.content);
      } else if (message.type === 'vote') {
        updateAgentVote(message.agent_id, message.vote);
      } else if (message.type === 'consensus') {
        setConsensus(message.consensus);
      }
    };
    
    return () => ws.close();
  }, [sessionId]);
  
  return (
    <div className="debate-interface">
      <DebateHeader question={session?.question} />
      <AgentGrid agents={session?.agents} />
      <DebateTimeline rounds={session?.rounds} />
      <VotingInterface votes={session?.currentVotes} />
      <ConsensusDisplay consensus={session?.consensus} />
    </div>
  );
};

// Template Selection Interface
const TemplateSelector: React.FC = () => {
  const [selectedTemplate, setSelectedTemplate] = useState<string | null>(null);
  const [customAgents, setCustomAgents] = useState<CustomAgent[]>([]);
  
  return (
    <div className="template-selector">
      <TemplateGrid 
        templates={AVAILABLE_TEMPLATES}
        onSelect={setSelectedTemplate}
      />
      
      {selectedTemplate === 'custom' && (
        <CustomAgentBuilder 
          agents={customAgents}
          onUpdate={setCustomAgents}
        />
      )}
      
      <DebateStarter 
        template={selectedTemplate}
        customAgents={customAgents}
      />
    </div>
  );
};
```

## ðŸš€ Deployment Architecture (TrueFoundry)

### **Production Deployment**

```yaml
# TrueFoundry deployment configuration
apiVersion: v1
kind: Service
metadata:
  name: dialectic-api
spec:
  selector:
    app: dialectic-api
  ports:
    - port: 8000
      targetPort: 8000
  type: LoadBalancer

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dialectic-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: dialectic-api
  template:
    metadata:
      labels:
        app: dialectic-api
    spec:
      containers:
      - name: dialectic-api
        image: dialectic/api:latest
        ports:
        - containerPort: 8000
        env:
        - name: REDPANDA_URL
          value: "redpanda://redpanda:9092"
        - name: AIRIA_API_KEY
          valueFrom:
            secretKeyRef:
              name: dialectic-secrets
              key: airia-api-key
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: dialectic-secrets
              key: openai-api-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"

---
apiVersion: v1
kind: Service
metadata:
  name: dialectic-frontend
spec:
  selector:
    app: dialectic-frontend
  ports:
    - port: 3000
      targetPort: 3000
  type: LoadBalancer

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dialectic-frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: dialectic-frontend
  template:
    metadata:
      labels:
        app: dialectic-frontend
    spec:
      containers:
      - name: dialectic-frontend
        image: dialectic/frontend:latest
        ports:
        - containerPort: 3000
        env:
        - name: API_URL
          value: "http://dialectic-api:8000"
```

## ðŸ”§ Integration Points

### **API Endpoints**

```python
# FastAPI Application
from fastapi import FastAPI, WebSocket, HTTPException
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Dialectic Framework API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/debate/template")
async def start_template_debate(
    template: str,
    question: str,
    custom_parameters: Dict = None
):
    """Start debate using predefined template"""
    
    # Validate template exists
    if template not in TEMPLATE_REGISTRY:
        raise HTTPException(status_code=400, detail="Invalid template")
    
    # Create agents from template
    agents = TEMPLATE_REGISTRY[template].create_agents(custom_parameters)
    
    # Start debate session
    session = await debate_orchestrator.start_debate(question, agents)
    
    return {
        "session_id": session.id,
        "question": question,
        "agents": [agent.to_dict() for agent in agents],
        "status": "active"
    }

@app.post("/debate/custom")
async def start_custom_debate(
    question: str,
    custom_agents: List[CustomAgentRequest]
):
    """Start debate with custom agents"""
    
    # Create custom agents
    agents = []
    for agent_request in custom_agents:
        agent = await custom_agent_builder.create_agent(
            name=agent_request.name,
            perspective=agent_request.perspective,
            expertise_domains=agent_request.expertise,
            voting_weight=agent_request.voting_weight
        )
        agents.append(agent)
    
    # Start debate session
    session = await debate_orchestrator.start_debate(question, agents)
    
    return {
        "session_id": session.id,
        "question": question,
        "agents": [agent.to_dict() for agent in agents],
        "status": "active"
    }

@app.websocket("/ws/debate/{session_id}")
async def debate_websocket(websocket: WebSocket, session_id: str):
    """WebSocket connection for real-time debate updates"""
    
    await websocket.accept()
    
    try:
        # Subscribe to debate streams
        consumer = await debate_streaming.subscribe_to_debate(
            session_id, 
            lambda message: websocket.send_text(json.dumps(message))
        )
        
        await consumer
        
    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected for session {session_id}")
```

## ðŸ“ˆ Performance Considerations

### **Scalability Architecture**

```python
class ScalabilityManager:
    """Manages system performance and scaling"""
    
    def __init__(self):
        self.active_sessions = {}
        self.performance_metrics = {}
    
    async def monitor_debate_performance(self, session_id: str):
        """Monitor debate performance and optimize"""
        
        metrics = {
            "response_times": [],
            "memory_usage": [],
            "agent_processing_times": {},
            "stream_latency": []
        }
        
        # Collect metrics during debate
        start_time = time.time()
        
        # Track agent response times
        for agent in self.active_sessions[session_id].agents:
            agent_start = time.time()
            await agent.process_message()
            agent_time = time.time() - agent_start
            
            metrics["agent_processing_times"][agent.role] = agent_time
        
        # Track stream latency
        stream_start = time.time()
        await self.stream_update(session_id, "performance_check")
        stream_time = time.time() - stream_start
        
        metrics["stream_latency"].append(stream_time)
        
        # Auto-scale if needed
        if self._should_scale(metrics):
            await self._trigger_scaling(session_id)
        
        return metrics
    
    def _should_scale(self, metrics: Dict) -> bool:
        """Determine if system needs scaling"""
        
        avg_response_time = sum(metrics["agent_processing_times"].values()) / len(metrics["agent_processing_times"])
        avg_stream_latency = sum(metrics["stream_latency"]) / len(metrics["stream_latency"])
        
        # Scale if response times exceed thresholds
        return avg_response_time > 2.0 or avg_stream_latency > 0.5
```

## ðŸ”’ Security & Privacy

### **Agent Isolation**

```python
class SecurityManager:
    """Manages security and privacy for agent interactions"""
    
    def __init__(self):
        self.agent_sandboxes = {}
        self.access_controls = {}
    
    async def create_agent_sandbox(self, agent: AgentTemplate) -> AgentSandbox:
        """Create isolated environment for agent execution"""
        
        sandbox = AgentSandbox(
            agent_id=agent.id,
            isolated_memory=True,
            restricted_api_access=True,
            audit_logging=True
        )
        
        # Set up access controls
        sandbox.allowed_apis = [
            "airia_knowledge_query",
            "redpanda_stream_publish",
            "openai_chat_completion"
        ]
        
        sandbox.blocked_apis = [
            "file_system_write",
            "network_outbound",
            "database_direct_access"
        ]
        
        self.agent_sandboxes[agent.id] = sandbox
        return sandbox
    
    async def audit_agent_actions(self, agent_id: str, action: str, details: Dict):
        """Audit all agent actions for security compliance"""
        
        audit_log = {
            "timestamp": datetime.utcnow().isoformat(),
            "agent_id": agent_id,
            "action": action,
            "details": details,
            "security_level": self._assess_security_level(action, details)
        }
        
        # Log to secure audit system
        await self.secure_logger.log(audit_log)
        
        # Check for suspicious patterns
        if self._detect_suspicious_activity(agent_id, audit_log):
            await self._quarantine_agent(agent_id)
```

---

This technical architecture provides the foundation for a scalable, secure, and extensible multi-agent reasoning framework that can handle any domain of debate while maintaining high performance and reliability.
